{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06848182-b979-4d3e-ab38-8144dc13ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c52e63-f48e-4968-b638-e1a6fafbeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([0.25 , 0.5 , 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1192633b-5bf7-499f-ab1b-315192ac89b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.5000, 0.0100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eed8f4c-138e-492b-ab23-e5a8c1491937",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_tensor = weight.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42016639-2089-429b-9b99-320666b6113d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500],\n",
       "        [0.5000],\n",
       "        [0.0100]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f908581-b7b0-49c9-ad58-c313514ae2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b8648a-a0c7-4156-bc08-7eac114e37f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_tensor[0 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0fe68ed-e2b0-4d4c-8f9c-e218ba3ae6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_tensor[1 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89f69039-87d4-4710-8595-000e0f7c0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn(2 , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1903db44-b225-4cda-8f21-bc0ce37e9f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2088, -0.3349,  0.8310],\n",
       "        [ 1.4131,  0.4377,  0.1917]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81bcc794-cf86-42e2-a800-8bf99d7e9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueezed_two_tensor = unsqueezed_tensor.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "797d8d53-b923-4e63-a7d5-066dc2e59a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2500]],\n",
       "\n",
       "        [[0.5000]],\n",
       "\n",
       "        [[0.0100]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_two_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a29c7aa8-d81d-489f-9155-520a94fae9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_two_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e8d5316-399f-45b0-b69f-c823ccce5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([1 , 2 , 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dd7c2e1-eb7d-44c6-9795-4b714a29b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 = torch.tensor([1 , 2 , 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac75e6f1-2cf5-41ef-ab01-b3fc62047bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor3 = tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e205eca-ead5-4088-b254-0002da35083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38325c74-a050-4971-976c-d719634c6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor4 = torch.tensor([\n",
    "    [1],\n",
    "    [2],\n",
    "    [3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c8fafd3-0ac1-48a7-b6a3-c8853d6e977c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "180b8131-400a-43ed-84fc-009242712ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5be2d4ab-2de4-4c90-b79f-a29600738b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 4, 6],\n",
       "        [3, 6, 9]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 * tensor4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74303f70-992a-4d48-a00c-ae3329b18b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1 , 2 , 3])\n",
    "b = torch.tensor([5 , 6 , 7])\n",
    "torch.einsum(\"i,i->\",a , b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39bf50a4-e5ea-4b86-ba20-2d2aa888d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "])  # shape: [2, 3] → we'll label axes as i (row), j (column)\n",
    "\n",
    "v = torch.tensor([10., 20., 30.])  # shape: [3] → label axis as j\n",
    "\n",
    "product = v * A\n",
    "sum = product.sum(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "472a5218-433c-457a-80fe-2cf7aafb2d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([140., 320.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31de4f3b-d37c-439b-8114-a0c5e5f7edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(2, 3, 4)\n",
    "weights = torch.tensor([10., 20., 30.])  # shape: [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59790bee-a971-406d-bc6d-975ac886053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_per_channel = weight.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9c90b18-9cba-4627-9be1-9cfd256728b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tensor * weights_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6667339f-0312-41a6-9c43-e991951f6bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.0100, 0.0100, 0.0100, 0.0100]],\n",
       "\n",
       "        [[0.2500, 0.2500, 0.2500, 0.2500],\n",
       "         [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "         [0.0100, 0.0100, 0.0100, 0.0100]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e675cfb8-7736-4258-a248-726c8f529840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor  tensor([-0.1951,  0.2498, -0.4251])\n",
      "weight tensor  tensor([-0.4848,  0.0505,  1.2852])\n",
      "after dot product and adding bias  tensor(0.1719)\n",
      "output item  0.1718977391719818\n"
     ]
    }
   ],
   "source": [
    "# manually creating my first neuron\n",
    "\n",
    "\n",
    "# input of size three \n",
    "input = torch.randn(3)\n",
    "print(\"input tensor \", input)\n",
    "# weights of the neuron, a value for each dimension in the input \n",
    "weights = torch.randn(3)\n",
    "print(\"weight tensor \", weights)\n",
    "# need a bias \n",
    "bias = torch.tensor(0.1)\n",
    "# get the value \n",
    "z = torch.dot(input, weight) + bias \n",
    "print(\"after dot product and adding bias \",z)\n",
    "# output from rel- u\n",
    "output = torch.maximum(z , torch.tensor(0.0))\n",
    "\n",
    "print(\"output item \",output.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67b75830-4222-4206-b566-fb2bc5f6ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_neuron(weight_tensor, bias, activation_function_callback):\n",
    "    if not isinstance(weight_tensor, torch.Tensor) or not isinstance(bias, torch.Tensor):\n",
    "        raise TypeError(\"Both weight_tensor and bias must be of type torch.Tensor\")\n",
    "    \n",
    "    if bias.dim() != 0:\n",
    "        raise ValueError(\"Bias must be a scalar (0-dimensional tensor)\")\n",
    "    \n",
    "    def neuron(input_tensor):\n",
    "        # Check if the dimensions match\n",
    "        if len(input_tensor) != len(weight_tensor):\n",
    "            raise ValueError(\"Dimensions of input_tensor and weight_tensor do not match\")\n",
    "        \n",
    "        output = torch.dot(weight_tensor, input_tensor) + bias\n",
    "        return activation_function_callback(output)\n",
    "    \n",
    "    return neuron\n",
    "\n",
    "def relu_activation_function(input):\n",
    "    if input.dim() != 0:\n",
    "        raise ValueError(\"dimension of the input needs to be zero\")\n",
    "    return torch.maximum(input , torch.tensor(0.0))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fff52a3d-2a41-4d25-a450-ec3a4ef5d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i need to connect layers\n",
    "# i need to forward propogate the neuron\n",
    "# the number of neurons in the layer decides the dimension of the output vector\n",
    "# a function needs to take the number neurons in the layer \n",
    "# that can be connected to any layer regardless of any number of neurons \n",
    "\n",
    "\n",
    "# connect_layer should connect both the layers\n",
    "# return a single layer \n",
    "def connect_layer(layer1 , layer2):\n",
    "    def combined_layer(input_tensor):\n",
    "        return layer2(layer1(input_tensor))\n",
    "\n",
    "    return combined_layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_layer(no_neurons, dimension_input_tensor, activation_function):\n",
    "    list_neurons = []\n",
    "    for _ in range(no_neurons):\n",
    "        weight = torch.randn(dimension_input_tensor)\n",
    "        bias = torch.randn(())\n",
    "        list_neurons.append(create_neuron(weight, bias, activation_function))\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        if len(input_tensor) != dimension_input_tensor:\n",
    "            raise ValueError(\"Input tensor size does not match expected dimension.\")\n",
    "        \n",
    "        return torch.tensor([neuron(input_tensor) for neuron in list_neurons])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6aea9c0d-62d9-42d9-b288-062b88218b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_1 = create_layer(5 , 3 , relu_activation_function)\n",
    "hidden_layer_2 = create_layer(3 , 5 , relu_activation_function)\n",
    "output_layer = create_layer(1 , 3, torch.sigmoid)\n",
    "\n",
    "c1 = connect_layer(hidden_layer_1 , hidden_layer_2)\n",
    "c2 = connect_layer(c1 , output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "41e3933f-9ebb-478d-91e4-b48d5157de8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3272])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer(torch.tensor([0.59 , 0.211, 0.11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3614b157-98af-40b4-b231-a6c96c86af87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
